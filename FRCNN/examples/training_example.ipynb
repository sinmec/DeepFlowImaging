{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d15ead-15b2-4dbe-9ab8-b252b4e46785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py as h5\n",
    "from pathlib import Path\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52817b45-d508-436d-9426-c8871e4b7154",
   "metadata": {},
   "source": [
    "# Training the F-RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f75659-2302-407a-b7d6-f9e798cddddf",
   "metadata": {},
   "source": [
    "## Importing auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38df3940-b87a-4dae-8f74-74584e6fd9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # TODO: fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91479b3a-7d08-44b5-94c3-520a7e037470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.read_dataset import read_dataset\n",
    "from training.create_anchors import create_anchors\n",
    "from training.calculate_bbox_intesect_over_union import calculate_bbox_intesect_over_union\n",
    "from training.evaluate_ious import evaluate_ious\n",
    "from training.create_samples_for_training import create_samples_for_training\n",
    "from training.parametrize_anchor_box_properties import parametrize_anchor_box_properties\n",
    "from training.losses import loss_cls, loss_reg\n",
    "from training.run import generate_validation_data\n",
    "from training.run import input_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752570d2-d5df-414d-8945-cdeb27774b3d",
   "metadata": {},
   "source": [
    "## Defining the path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3fff21-0896-48fa-b3c5-2fa7a9fce71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = Path(\"dataset_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac844f6b-1f83-4eba-b2b3-3254382d6fe8",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e51ade8-7a45-46a1-8128-4efe6533cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (500, 500)\n",
    "imgs, bbox_datasets = read_dataset(IMG_SIZE, dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9442705-43a9-4d6a-a75e-d601589d725b",
   "metadata": {},
   "source": [
    "## Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f1ece1-1cb3-4a05-b18d-53b40d829d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e47de3-e187-49ae-9297-5964dee97538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling dataset\n",
    "N_dataset = imgs.shape[0]\n",
    "array_for_shuffling = np.arange(N_dataset, dtype=int)\n",
    "random.Random(RANDOM_SEED).shuffle(array_for_shuffling)\n",
    "\n",
    "# Shuffling images\n",
    "imgs = imgs[array_for_shuffling]\n",
    "\n",
    "# Shuffling bboxes\n",
    "bbox_datasets_new = []\n",
    "for new_index in array_for_shuffling:\n",
    "    bbox_datasets_new.append(bbox_datasets[new_index])\n",
    "bbox_datasets = bbox_datasets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02f19b79-5a31-401a-9f55-6de48cb09618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining which image is used during training\n",
    "MODE = \"mask\"\n",
    "if MODE == \"mask\":\n",
    "    imgs = imgs[:,:,:,0]\n",
    "elif MODE == \"raw\":\n",
    "    imgs = imgs[:,:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073bf1f-d5ad-4a87-90e9-f43357a64aac",
   "metadata": {},
   "source": [
    "## Defining some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10050384-3baa-4ff2-8e52-263b2c259ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SUB = 8\n",
    "ANCHOR_REAL_SIZE = [16, 24, 32, 48, 64]\n",
    "POS_IOU_THRESHOLD = 0.50\n",
    "NEG_IOU_THRESHOLD = 0.1\n",
    "N_FILTERS = 16\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "ANCHOR_RATIOS = [0.5, 0.8, 1.0, 1.1]\n",
    "\n",
    "SHOW_N_POS = False\n",
    "POS_RATIO = 0.5\n",
    "N_SAMPLES = 30\n",
    "\n",
    "ADAM_LEARNING_RATE = 3.0e-4\n",
    "\n",
    "# Subscaling/Anchor values (2^n), ex: 1, 2, 4, 8, 16, 32\n",
    "N_SUB = 2\n",
    "\n",
    "# Defining anchor sizes\n",
    "ANCHOR_SIZES = np.array(ANCHOR_REAL_SIZE) // N_SUB\n",
    "\n",
    "# Defining number of anchors sized and rations\n",
    "N_ANCHORS =  len(ANCHOR_SIZES)\n",
    "N_RATIOS  =  len(ANCHOR_RATIOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90d346-466d-46a7-9f37-0cbd65d6e5ef",
   "metadata": {},
   "source": [
    "## Defining the F-RCNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e6fcd2-68c5-4cc9-95ce-886a8f5920d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMG_SIZE[0],IMG_SIZE[1],1))\n",
    "\n",
    "conv_3_3_1 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-1\"\n",
    "    )(input_image)\n",
    "max_pool_1 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_1\")(conv_3_3_1)\n",
    "\n",
    "conv_3_3_2 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-2\"\n",
    ")(max_pool_1)\n",
    "\n",
    "\n",
    "max_pool_2 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_2\")(conv_3_3_2)\n",
    "\n",
    "conv_3_3_3 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-3\"\n",
    ")(max_pool_2)\n",
    "\n",
    "max_pool_3 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_3\")(conv_3_3_3)\n",
    "\n",
    "conv_3_3_4 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-4\"\n",
    ")(max_pool_3)\n",
    "\n",
    "max_pool_4 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_4\")(conv_3_3_4)\n",
    "\n",
    "conv_3_3_5 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-5\"\n",
    ")(max_pool_4)\n",
    "\n",
    "max_pool_5 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_5\")(conv_3_3_5)\n",
    "\n",
    "conv_3_3_6 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-6\"\n",
    ")(max_pool_5)\n",
    "\n",
    "max_pool_6 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_6\")(conv_3_3_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc9f97e-291b-4e29-ac2d-04bf3b08ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SUB = 8\n",
    "\n",
    "if N_SUB == 1:\n",
    "    last_layer = conv_3_3_1\n",
    "elif N_SUB == 2:\n",
    "    last_layer = max_pool_1\n",
    "elif N_SUB == 4:\n",
    "    last_layer = max_pool_2\n",
    "elif N_SUB == 8:\n",
    "    last_layer = max_pool_3\n",
    "elif N_SUB == 16:\n",
    "    last_layer = max_pool_4\n",
    "elif N_SUB == 32:\n",
    "    last_layer = max_pool_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b09bd49-4060-4f21-b871-476ac2cfe4c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_scores = Conv2D(\n",
    "    filters=N_ANCHORS * N_RATIOS,\n",
    "    kernel_size=(1, 1),\n",
    "    activation=\"sigmoid\",\n",
    "    kernel_initializer=\"uniform\",\n",
    "    name=\"l_reg\"\n",
    ")(last_layer)\n",
    "\n",
    "output_regressor = Conv2D(\n",
    "    filters=N_ANCHORS * N_RATIOS * 4,\n",
    "    kernel_size=(1, 1),\n",
    "    activation=\"linear\",\n",
    "    kernel_initializer=\"uniform\",\n",
    "    name=\"bb_reg\"\n",
    ")(last_layer)\n",
    "\n",
    "opt = Adam(learning_rate=ADAM_LEARNING_RATE)\n",
    "model = Model(inputs=[input_image], outputs=[output_scores, output_regressor])\n",
    "model.compile(optimizer=opt, loss={'l_reg':loss_cls, 'bb_reg':loss_reg})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ab4f4-e64a-413c-84d3-6cb4c619b74f",
   "metadata": {},
   "source": [
    "Below we can get a summary of the model. Alternatively (and recommended), you can check the F-RCNN architecture with Keras' `plot_model` function (see [here](https://keras.io/api/utils/model_plotting_utils/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8761778e-cef1-4003-8219-9035bef81437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 500, 500, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "3x3-1 (Conv2D)                  (None, 500, 500, 16) 416         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_1 (MaxPooling2D)       (None, 250, 250, 16) 0           3x3-1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "3x3-2 (Conv2D)                  (None, 250, 250, 16) 6416        max_pool_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_2 (MaxPooling2D)       (None, 125, 125, 16) 0           3x3-2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "3x3-3 (Conv2D)                  (None, 125, 125, 16) 6416        max_pool_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_3 (MaxPooling2D)       (None, 62, 62, 16)   0           3x3-3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "l_reg (Conv2D)                  (None, 62, 62, 20)   340         max_pool_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bb_reg (Conv2D)                 (None, 62, 62, 80)   1360        max_pool_3[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 14,948\n",
      "Trainable params: 14,948\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851aff2e-8b2c-4dbd-8a18-7deb1aec4292",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f5889-98e3-40f8-b371-ca6e6798eb83",
   "metadata": {},
   "source": [
    "Now, we need to setup a few callbacks to be executed during training.\n",
    "\n",
    "The first one is the `early_stopping` callback, which defines a `PATIENCE` value to limit the number of running epochs (`EPOCHS`).\n",
    "\n",
    "The second one, `best_model`, is a callback to store the F-RCNN with the lowest validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e69ef3-ef7e-4692-8952-c9726a47b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "N_PATIENCE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429ad122-736b-4c78-8820-4f0864d04841",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VALIDATION_DATA = 10\n",
    "N_DATA_EPOCHS = 10\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d738613-ce20-4bdf-ae10-221b55fba0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the best fRCNN model name\n",
    "best_model_name = \"best_fRCNN_%s_%02d.keras\" % (MODE, N_SUB)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               mode='min',\n",
    "                               verbose=1,\n",
    "                               patience=N_PATIENCE)\n",
    "\n",
    "best_model = ModelCheckpoint(best_model_name,\n",
    "                              verbose=1,\n",
    "                              save_best_only=True,\n",
    "                              monitor='val_loss',\n",
    "                              mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78437b-3521-49f5-a459-efc731724436",
   "metadata": {},
   "source": [
    "On this function below, it will generate the validation data necessary to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75b804f-7944-4058-8935-6c209373a038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation data: 10it [00:01,  6.43it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_data = generate_validation_data(imgs[:N_VALIDATION_DATA],\n",
    "                                           bbox_datasets[:N_VALIDATION_DATA],\n",
    "                                           IMG_SIZE,\n",
    "                                           N_SUB,\n",
    "                                           N_ANCHORS,\n",
    "                                           ANCHOR_SIZES,\n",
    "                                           ANCHOR_RATIOS,\n",
    "                                           N_RATIOS,\n",
    "                                           POS_IOU_THRESHOLD,\n",
    "                                           NEG_IOU_THRESHOLD,\n",
    "                                           DEBUG,\n",
    "                                           POS_RATIO,\n",
    "                                           N_SAMPLES,\n",
    "                                           SHOW_N_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8e009-e13e-4e4f-b3f2-a3793b1db1d9",
   "metadata": {},
   "source": [
    "Now, it's time to train the model with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90ddd41d-6a10-40c4-844c-5911bc3a1f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15  5 11  5 12  8 16  5  0 10]\n",
      "Epoch 1/100\n",
      "[15  5 11  5 12  8 16  5  0 10]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6931 - l_reg_loss: 0.6931 - bb_reg_loss: 3.9858e-06[15  5 11  5 12  8 16  5  0 10]\n",
      " 2/10 [=====>........................] - ETA: 4s - loss: 0.6931 - l_reg_loss: 0.6931 - bb_reg_loss: 4.2716e-06[15  5 11  5 12  8 16  5  0 10]\n",
      " 3/10 [========>.....................] - ETA: 5s - loss: 0.6930 - l_reg_loss: 0.6930 - bb_reg_loss: 5.7821e-06[15  5 11  5 12  8 16  5  0 10]\n",
      " 4/10 [===========>..................] - ETA: 5s - loss: 0.6929 - l_reg_loss: 0.6929 - bb_reg_loss: 6.8998e-06[15  5 11  5 12  8 16  5  0 10]\n",
      " 5/10 [==============>...............] - ETA: 4s - loss: 0.6928 - l_reg_loss: 0.6928 - bb_reg_loss: 1.0424e-05[15  5 11  5 12  8 16  5  0 10]\n",
      " 6/10 [=================>............] - ETA: 3s - loss: 0.6927 - l_reg_loss: 0.6926 - bb_reg_loss: 1.5339e-05[15  5 11  5 12  8 16  5  0 10]\n",
      " 7/10 [====================>.........] - ETA: 2s - loss: 0.6926 - l_reg_loss: 0.6925 - bb_reg_loss: 2.0743e-05[15  5 11  5 12  8 16  5  0 10]\n",
      " 8/10 [=======================>......] - ETA: 1s - loss: 0.6924 - l_reg_loss: 0.6924 - bb_reg_loss: 2.8101e-05[15  5 11  5 12  8 16  5  0 10]\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.6923 - l_reg_loss: 0.6923 - bb_reg_loss: 4.6196e-05[ 2  1  8  6 12  6  1  1 14  0]\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7137 - l_reg_loss: 0.6922 - bb_reg_loss: 0.0215    \n",
      "Epoch 00001: val_loss improved from inf to 0.92446, saving model to best_fRCNN_mask_08.keras\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7137 - l_reg_loss: 0.6922 - bb_reg_loss: 0.0215 - val_loss: 0.9245 - val_l_reg_loss: 0.6918 - val_bb_reg_loss: 0.2326\n",
      "Epoch 2/100\n",
      "[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6908 - l_reg_loss: 0.6908 - bb_reg_loss: 1.5409e-06[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 2/10 [=====>........................] - ETA: 5s - loss: 0.6906 - l_reg_loss: 0.6906 - bb_reg_loss: 1.8955e-06[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 3/10 [========>.....................] - ETA: 5s - loss: 0.6905 - l_reg_loss: 0.6905 - bb_reg_loss: 4.0035e-06[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 4/10 [===========>..................] - ETA: 5s - loss: 0.6904 - l_reg_loss: 0.6904 - bb_reg_loss: 5.5733e-06[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 5/10 [==============>...............] - ETA: 4s - loss: 0.6902 - l_reg_loss: 0.6902 - bb_reg_loss: 9.4456e-06[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 6/10 [=================>............] - ETA: 3s - loss: 0.6901 - l_reg_loss: 0.6900 - bb_reg_loss: 1.3134e-05[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 7/10 [====================>.........] - ETA: 2s - loss: 0.6899 - l_reg_loss: 0.6899 - bb_reg_loss: 1.7228e-05[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 8/10 [=======================>......] - ETA: 1s - loss: 0.6897 - l_reg_loss: 0.6897 - bb_reg_loss: 2.2611e-05[ 2  1  8  6 12  6  1  1 14  0]\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 0.6895 - l_reg_loss: 0.6895 - bb_reg_loss: 3.6091e-05[ 4  7  4  1  2  0  2 12 16  3]\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7096 - l_reg_loss: 0.6893 - bb_reg_loss: 0.0203    \n",
      "Epoch 00002: val_loss improved from 0.92446 to 0.91236, saving model to best_fRCNN_mask_08.keras\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7096 - l_reg_loss: 0.6893 - bb_reg_loss: 0.0203 - val_loss: 0.9124 - val_l_reg_loss: 0.6890 - val_bb_reg_loss: 0.2234\n",
      "Epoch 3/100\n",
      "[ 4  7  4  1  2  0  2 12 16  3]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6871 - l_reg_loss: 0.6871 - bb_reg_loss: 2.7026e-05[ 4  7  4  1  2  0  2 12 16  3]\n",
      " 2/10 [=====>........................] - ETA: 4s - loss: 0.6868 - l_reg_loss: 0.6868 - bb_reg_loss: 3.2199e-05[ 4  7  4  1  2  0  2 12 16  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(input_generator(imgs[N_VALIDATION_DATA:],\n",
    "                          bbox_datasets[N_VALIDATION_DATA:],\n",
    "                          IMG_SIZE,\n",
    "                          N_SUB,\n",
    "                          ANCHOR_RATIOS,\n",
    "                          ANCHOR_SIZES,\n",
    "                          N_DATA_EPOCHS,\n",
    "                          N_ANCHORS,\n",
    "                          N_RATIOS,\n",
    "                          POS_IOU_THRESHOLD,\n",
    "                          NEG_IOU_THRESHOLD,\n",
    "                          DEBUG, \n",
    "                          POS_RATIO,\n",
    "                          N_SAMPLES,\n",
    "                          SHOW_N_POS),\n",
    "          steps_per_epoch=10,\n",
    "          epochs=N_EPOCHS,\n",
    "          callbacks=[best_model, early_stopping],\n",
    "          validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ebd5bc-1de0-4a39-84aa-123e07756c35",
   "metadata": {},
   "source": [
    "At this point, the model is trained. In order to use the model as a segmentation tool, please check the `predicting_example`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e9be6-d297-44d5-bc33-9d4ff3a4c5de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
