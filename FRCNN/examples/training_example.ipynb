{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d15ead-15b2-4dbe-9ab8-b252b4e46785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py as h5\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52817b45-d508-436d-9426-c8871e4b7154",
   "metadata": {},
   "source": [
    "# Training the F-RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f75659-2302-407a-b7d6-f9e798cddddf",
   "metadata": {},
   "source": [
    "## Importing auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38df3940-b87a-4dae-8f74-74584e6fd9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\") # TODO: fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91479b3a-7d08-44b5-94c3-520a7e037470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.read_dataset import read_dataset\n",
    "from training.create_anchors import create_anchors\n",
    "from training.calculate_bbox_intesect_over_union import calculate_bbox_intesect_over_union\n",
    "from training.evaluate_ious import evaluate_ious\n",
    "from training.create_samples_for_training import create_samples_for_training\n",
    "from training.parametrize_anchor_box_properties import parametrize_anchor_box_properties\n",
    "from training.losses import loss_cls, loss_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6278f-f90c-4153-8db2-bf161d9d636e",
   "metadata": {},
   "source": [
    "## Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeafe72e-b589-4b2a-be42-464aaa3a4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RATIO_LOSSES = 10.0\n",
    "N_VALIDATION_DATA = 10\n",
    "N_TEST_DATA = 5\n",
    "N_DATA_EPOCHS = 10\n",
    "N_EPOCHS = 100\n",
    "N_PATIENCE = 200\n",
    "RANDOM_SEED = 13\n",
    "\n",
    "IMG_SIZE = (500, 500)\n",
    "MODE = \"mask\"\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "N_SUB = 8\n",
    "ANCHOR_REAL_SIZE = [16, 24, 32, 48, 64]\n",
    "POS_IOU_THRESHOLD = 0.50\n",
    "NEG_IOU_THRESHOLD = 0.1\n",
    "N_FILTERS = 16\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "ANCHOR_RATIOS = [0.5, 0.8, 1.0, 1.1]\n",
    "\n",
    "SHOW_N_POS = False\n",
    "POS_RATIO = 0.5\n",
    "N_SAMPLES = 30\n",
    "\n",
    "ADAM_LEARNING_RATE = 3.0e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e47de3-e187-49ae-9297-5964dee97538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# Loading image size from config file\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "# Subscaling/Anchor values (2^n), ex: 1, 2, 4, 8, 16, 32\n",
    "N_SUB = 2\n",
    "\n",
    "# Defining anchor sizes\n",
    "ANCHOR_SIZES = np.array(ANCHOR_REAL_SIZE) // N_SUB\n",
    "\n",
    "# Defining number of anchors sized and rations\n",
    "N_ANCHORS =  len(ANCHOR_SIZES)\n",
    "N_RATIOS  =  len(ANCHOR_RATIOS)\n",
    "\n",
    "# Defining the dataset folder\n",
    "dataset_folder = \"dataset_test\"\n",
    "imgs, bbox_datasets = read_dataset(img_size, dataset_folder)\n",
    "\n",
    "# Shuffling dataset - random seed is 13\n",
    "N_dataset = imgs.shape[0]\n",
    "array_for_shuffling = np.arange(N_dataset, dtype=int)\n",
    "random.Random(13).shuffle(array_for_shuffling)\n",
    "\n",
    "# Shuffling images\n",
    "imgs = imgs[array_for_shuffling]\n",
    "\n",
    "# Shuffling bboxes\n",
    "bbox_datasets_new = []\n",
    "for new_index in array_for_shuffling:\n",
    "    bbox_datasets_new.append(bbox_datasets[new_index])\n",
    "bbox_datasets = bbox_datasets_new\n",
    "\n",
    "# Defining which image is used during training\n",
    "if MODE == \"mask\":\n",
    "    imgs = imgs[:,:,:,0]\n",
    "elif MODE == \"raw\":\n",
    "    imgs = imgs[:,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e6fcd2-68c5-4cc9-95ce-886a8f5920d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(img_size[0],img_size[1],1))\n",
    "conv_3_3_1 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-1\"\n",
    "    )(input_image)\n",
    "max_pool_1 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_1\")(conv_3_3_1)\n",
    "\n",
    "conv_3_3_2 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-2\"\n",
    ")(max_pool_1)\n",
    "\n",
    "\n",
    "max_pool_2 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_2\")(conv_3_3_2)\n",
    "\n",
    "conv_3_3_3 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-3\"\n",
    ")(max_pool_2)\n",
    "\n",
    "max_pool_3 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_3\")(conv_3_3_3)\n",
    "\n",
    "conv_3_3_4 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-4\"\n",
    ")(max_pool_3)\n",
    "\n",
    "max_pool_4 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_4\")(conv_3_3_4)\n",
    "\n",
    "conv_3_3_5 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-5\"\n",
    ")(max_pool_4)\n",
    "\n",
    "max_pool_5 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_5\")(conv_3_3_5)\n",
    "\n",
    "conv_3_3_6 = Conv2D(\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    padding='same',\n",
    "    name=\"3x3-6\"\n",
    ")(max_pool_5)\n",
    "\n",
    "max_pool_6 = MaxPooling2D((2,2),\n",
    "                          name=\"max_pool_6\")(conv_3_3_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc9f97e-291b-4e29-ac2d-04bf3b08ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_SUB == 1:\n",
    "    last_layer = conv_3_3_1\n",
    "elif N_SUB == 2:\n",
    "    last_layer = max_pool_1\n",
    "elif N_SUB == 4:\n",
    "    last_layer = max_pool_2\n",
    "elif N_SUB == 8:\n",
    "    last_layer = max_pool_3\n",
    "elif N_SUB == 16:\n",
    "    last_layer = max_pool_4\n",
    "elif N_SUB == 32:\n",
    "    last_layer = max_pool_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b09bd49-4060-4f21-b871-476ac2cfe4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 500, 500, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "3x3-1 (Conv2D)                  (None, 500, 500, 16) 416         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_1 (MaxPooling2D)       (None, 250, 250, 16) 0           3x3-1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "l_reg (Conv2D)                  (None, 250, 250, 20) 340         max_pool_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bb_reg (Conv2D)                 (None, 250, 250, 80) 1360        max_pool_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,116\n",
      "Trainable params: 2,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_scores = Conv2D(\n",
    "    filters=N_ANCHORS * N_RATIOS,\n",
    "    kernel_size=(1, 1),\n",
    "    activation=\"sigmoid\",\n",
    "    kernel_initializer=\"uniform\",\n",
    "    name=\"l_reg\"\n",
    ")(last_layer)\n",
    "\n",
    "output_regressor = Conv2D(\n",
    "    filters=N_ANCHORS * N_RATIOS * 4,\n",
    "    kernel_size=(1, 1),\n",
    "    activation=\"linear\",\n",
    "    kernel_initializer=\"uniform\",\n",
    "    name=\"bb_reg\"\n",
    ")(last_layer)\n",
    "\n",
    "opt = Adam(learning_rate=ADAM_LEARNING_RATE)\n",
    "model = Model(inputs=[input_image], outputs=[output_scores, output_regressor])\n",
    "model.compile(optimizer=opt, loss={'l_reg':loss_cls, 'bb_reg':loss_reg})\n",
    "\n",
    "\n",
    "plot_model(model, show_shapes=True, to_file=\"model_true.png\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf81557e-6460-4dac-9799-9e480b12acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_data(imgs, bbox_datasets, img_size, N_SUB, N_ANCHORS, ANCHOR_SIZES, ANCHOR_RATIOS, N_RATIOS,\n",
    "                             POS_IOU_THRESHOLD, NEG_IOU_THRESHOLD, DEBUG, POS_RATIO, N_SAMPLES, SHOW_N_POS):\n",
    "\n",
    "    # Creating the anchors\n",
    "    anchors, index_anchors_valid = create_anchors(img_size, N_SUB, ANCHOR_RATIOS, ANCHOR_SIZES, imgs[0])\n",
    "\n",
    "    # Number of validation images\n",
    "    N_validation = imgs.shape[0]\n",
    "\n",
    "    # Initializing the arrays\n",
    "    batch_imgs             = np.zeros((N_validation, img_size[0], img_size[1], 1), dtype=np.float64)\n",
    "    batch_anchor_labels    = np.zeros((N_validation, img_size[0] // N_SUB, img_size[1] // N_SUB, N_ANCHORS * N_RATIOS),     dtype=np.float64)\n",
    "    batch_anchor_locations = np.zeros((N_validation, img_size[0] // N_SUB, img_size[1] // N_SUB, 4 * N_ANCHORS * N_RATIOS), dtype=np.float64)\n",
    "\n",
    "    index = 0\n",
    "    for img, bbox_dataset in zip(imgs, bbox_datasets):\n",
    "\n",
    "        # Calculating anchor/bbox_dataset IoUs\n",
    "        ious = calculate_bbox_intesect_over_union(anchors, index_anchors_valid, bbox_dataset, img)\n",
    "\n",
    "        # Evaluating if the anchors are valid or invalid based on the IoUs\n",
    "        labels, anchor_argmax_ious = evaluate_ious(anchors, index_anchors_valid, ious, bbox_dataset, img, POS_IOU_THRESHOLD, NEG_IOU_THRESHOLD, debug=DEBUG)\n",
    "\n",
    "        # Creating the samples for training\n",
    "        anchor_labels = create_samples_for_training(anchors, index_anchors_valid, anchor_argmax_ious, labels, ious, bbox_dataset, img,\n",
    "                                                    POS_RATIO, N_SAMPLES, SHOW_N_POS, debug=DEBUG)\n",
    "\n",
    "        # Reshaping the anchor labels to follow the image/sub-image coordinates\n",
    "        anchor_labels = np.reshape(anchor_labels, (img_size[0] // N_SUB, img_size[1] // N_SUB, N_ANCHORS * N_RATIOS))\n",
    "\n",
    "        # Parametrizing the anchor box properties\n",
    "        anchor_locations = parametrize_anchor_box_properties(anchors, anchor_argmax_ious, labels, ious, bbox_dataset, img)\n",
    "\n",
    "        # Reshaping the anchor locations to follow the image/sub-image coordinates\n",
    "        anchor_locations = np.reshape(anchor_locations, (img_size[0] // N_SUB, img_size[1] // N_SUB, 4 * N_ANCHORS * N_RATIOS))\n",
    "\n",
    "        # Converting to float\n",
    "        anchor_labels = anchor_labels.astype(np.float64)\n",
    "\n",
    "        # Storing images\n",
    "        batch_imgs[index, :, :, 0] = img\n",
    "\n",
    "        # Updating anchor labels and properties(locations)\n",
    "        batch_anchor_labels[index,:,:,:] = anchor_labels\n",
    "        batch_anchor_locations[index,:,:,:] = anchor_locations\n",
    "\n",
    "        index+=1\n",
    "        print(index)\n",
    "\n",
    "    # Returning samples for model validation\n",
    "    return batch_imgs, [batch_anchor_labels, batch_anchor_locations]\n",
    "\n",
    "def input_generator(imgs, bbox_datasets, img_size, N_SUB, ANCHOR_RATIOS, ANCHOR_SIZES, N_DATA_EPOCHS, N_ANCHORS, N_RATIOS,\n",
    "                    POS_IOU_THRESHOLD, NEG_IOU_THRESHOLD, DEBUG, POS_RATIO, N_SAMPLES, SHOW_N_POS):\n",
    "\n",
    "    # Creating the anchors\n",
    "    anchors, index_anchors_valid = create_anchors(img_size, N_SUB, ANCHOR_RATIOS, ANCHOR_SIZES, imgs[0])\n",
    "\n",
    "\n",
    "    while True:\n",
    "        # Picking a random number of images for training\n",
    "        random_indexes = np.random.randint(low=0, high=len(imgs)-1, size=N_DATA_EPOCHS)\n",
    "        # Initializing the arrays\n",
    "        batch_imgs             = np.zeros((len(random_indexes), img_size[0], img_size[1], 1), dtype=np.float64)\n",
    "        batch_anchor_labels    = np.zeros((len(random_indexes), img_size[0] // N_SUB, img_size[1] // N_SUB, N_ANCHORS * N_RATIOS),     dtype=np.float64)\n",
    "        batch_anchor_locations = np.zeros((len(random_indexes), img_size[0] // N_SUB, img_size[1] // N_SUB, 4 * N_ANCHORS * N_RATIOS), dtype=np.float64)\n",
    "\n",
    "        # Looping over the selected indexes and generating the input dataset\n",
    "        for k, random_index in enumerate(random_indexes):\n",
    "\n",
    "            # Retriegving the image and the bbox-values\n",
    "            img = imgs[random_index]\n",
    "            bbox_dataset = bbox_datasets[random_index]\n",
    "\n",
    "            # Calculating anchor/bbox_dataset IoUs\n",
    "            ious = calculate_bbox_intesect_over_union(anchors, index_anchors_valid, bbox_dataset, img)\n",
    "\n",
    "            # Evaluating if the anchors are valid or invalid based on the IoUs\n",
    "            labels, anchor_argmax_ious = evaluate_ious(anchors, index_anchors_valid, ious, bbox_dataset, img, POS_IOU_THRESHOLD, NEG_IOU_THRESHOLD, debug=DEBUG)\n",
    "\n",
    "            # Creating the samples for training\n",
    "\n",
    "            anchor_labels = create_samples_for_training(anchors, index_anchors_valid, anchor_argmax_ious, labels, ious, bbox_dataset, img,\n",
    "                                                        POS_RATIO, N_SAMPLES, SHOW_N_POS, debug=False)\n",
    "\n",
    "            # Reshaping the anchor labels to follow the image/sub-image coordinates\n",
    "            anchor_labels = np.reshape(anchor_labels, (img_size[0] // N_SUB, img_size[1] // N_SUB, N_ANCHORS * N_RATIOS))\n",
    "\n",
    "            # Parametrizing the anchor box properties\n",
    "            anchor_locations = parametrize_anchor_box_properties(anchors, anchor_argmax_ious, labels, ious, bbox_dataset, img)\n",
    "\n",
    "            # Reshaping the anchor locations to follow the image/sub-image coordinates\n",
    "            anchor_locations = np.reshape(anchor_locations, (img_size[0] // N_SUB, img_size[1] // N_SUB, 4 * N_ANCHORS * N_RATIOS))\n",
    "\n",
    "            # Converting to float\n",
    "            anchor_labels = anchor_labels.astype(np.float64)\n",
    "\n",
    "            # Storing images\n",
    "            batch_imgs[k, :, :, 0] = img\n",
    "\n",
    "            print(random_indexes)\n",
    "\n",
    "            # Updating anchor labels and properties(locations)\n",
    "            batch_anchor_labels[k,:,:,:] = anchor_labels\n",
    "            batch_anchor_locations[k,:,:,:] = anchor_locations\n",
    "\n",
    "            # Returning/Yielding samples for model training\n",
    "            yield batch_imgs, (batch_anchor_labels, batch_anchor_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d738613-ce20-4bdf-ae10-221b55fba0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "[ 4 13  9  6  8  7  4 14 12  5]\n",
      "Epoch 1/100\n",
      "[ 4 13  9  6  8  7  4 14 12  5]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6931 - l_reg_loss: 0.6931 - bb_reg_loss: 2.1623e-07[ 4 13  9  6  8  7  4 14 12  5]\n",
      " 2/10 [=====>........................] - ETA: 21s - loss: 0.6931 - l_reg_loss: 0.6931 - bb_reg_loss: 3.4429e-07[ 4 13  9  6  8  7  4 14 12  5]\n",
      " 4/10 [===========>..................] - ETA: 21s - loss: 0.6929 - l_reg_loss: 0.6929 - bb_reg_loss: 7.6466e-07[ 4 13  9  6  8  7  4 14 12  5]\n",
      "[ 4 13  9  6  8  7  4 14 12  5]\n",
      " 5/10 [==============>...............] - ETA: 18s - loss: 0.6928 - l_reg_loss: 0.6928 - bb_reg_loss: 1.0268e-06[ 4 13  9  6  8  7  4 14 12  5]\n",
      " 6/10 [=================>............] - ETA: 14s - loss: 0.6927 - l_reg_loss: 0.6927 - bb_reg_loss: 1.3796e-06[ 4 13  9  6  8  7  4 14 12  5]\n",
      " 8/10 [=======================>......] - ETA: 6s - loss: 0.6926 - l_reg_loss: 0.6926 - bb_reg_loss: 2.7815e-06 [ 4 13  9  6  8  7  4 14 12  5]\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 0.6925 - l_reg_loss: 0.6925 - bb_reg_loss: 4.7171e-06[ 4 13  9  6  8  7  4 14 12  5]\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7110 - l_reg_loss: 0.6926 - bb_reg_loss: 0.0184    [14 13  6  8 14 15 14  5 14  9]\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.88242, saving model to best_fRCNN_mask_02.keras\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.7110 - l_reg_loss: 0.6926 - bb_reg_loss: 0.0184 - val_loss: 0.8824 - val_l_reg_loss: 0.6932 - val_bb_reg_loss: 0.1892\n",
      "Epoch 2/100\n",
      "[14 13  6  8 14 15 14  5 14  9]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6915 - l_reg_loss: 0.6915 - bb_reg_loss: 4.0629e-07[14 13  6  8 14 15 14  5 14  9]\n",
      " 2/10 [=====>........................] - ETA: 17s - loss: 0.6914 - l_reg_loss: 0.6914 - bb_reg_loss: 7.2112e-07[14 13  6  8 14 15 14  5 14  9]\n",
      " 3/10 [========>.....................] - ETA: 20s - loss: 0.6914 - l_reg_loss: 0.6914 - bb_reg_loss: 1.1147e-06[14 13  6  8 14 15 14  5 14  9]\n",
      " 4/10 [===========>..................] - ETA: 18s - loss: 0.6913 - l_reg_loss: 0.6913 - bb_reg_loss: 1.5506e-06[14 13  6  8 14 15 14  5 14  9]\n",
      " 5/10 [==============>...............] - ETA: 15s - loss: 0.6912 - l_reg_loss: 0.6912 - bb_reg_loss: 2.0535e-06[14 13  6  8 14 15 14  5 14  9]\n",
      " 6/10 [=================>............] - ETA: 12s - loss: 0.6911 - l_reg_loss: 0.6911 - bb_reg_loss: 2.6626e-06[14 13  6  8 14 15 14  5 14  9]\n",
      " 8/10 [=======================>......] - ETA: 5s - loss: 0.6910 - l_reg_loss: 0.6910 - bb_reg_loss: 4.5335e-06[14 13  6  8 14 15 14  5 14  9]\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 0.6909 - l_reg_loss: 0.6909 - bb_reg_loss: 6.6992e-06[14 13  6  8 14 15 14  5 14  9]\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7094 - l_reg_loss: 0.6911 - bb_reg_loss: 0.0183    \n",
      "Epoch 00002: val_loss improved from 0.88242 to 0.88113, saving model to best_fRCNN_mask_02.keras\n",
      "[ 7  8 12  1  7  0 16 15 10 10]\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.7094 - l_reg_loss: 0.6911 - bb_reg_loss: 0.0183 - val_loss: 0.8811 - val_l_reg_loss: 0.6931 - val_bb_reg_loss: 0.1880\n",
      "Epoch 3/100\n",
      "[ 7  8 12  1  7  0 16 15 10 10]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6899 - l_reg_loss: 0.6899 - bb_reg_loss: 4.8440e-06[ 7  8 12  1  7  0 16 15 10 10]\n",
      " 2/10 [=====>........................] - ETA: 22s - loss: 0.6898 - l_reg_loss: 0.6898 - bb_reg_loss: 5.3796e-06[ 7  8 12  1  7  0 16 15 10 10]\n",
      " 3/10 [========>.....................] - ETA: 23s - loss: 0.6897 - l_reg_loss: 0.6897 - bb_reg_loss: 5.9569e-06[ 7  8 12  1  7  0 16 15 10 10]\n",
      " 4/10 [===========>..................] - ETA: 19s - loss: 0.6897 - l_reg_loss: 0.6897 - bb_reg_loss: 6.5861e-06[ 7  8 12  1  7  0 16 15 10 10]\n",
      " 5/10 [==============>...............] - ETA: 16s - loss: 0.6896 - l_reg_loss: 0.6896 - bb_reg_loss: 7.2855e-06[ 7  8 12  1  7  0 16 15 10 10]\n",
      " 6/10 [=================>............] - ETA: 12s - loss: 0.6895 - l_reg_loss: 0.6895 - bb_reg_loss: 8.0593e-06[ 7  8 12  1  7  0 16 15 10 10]\n",
      " 7/10 [====================>.........] - ETA: 8s - loss: 0.6894 - l_reg_loss: 0.6894 - bb_reg_loss: 8.9631e-06 [ 7  8 12  1  7  0 16 15 10 10]\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 0.6892 - l_reg_loss: 0.6892 - bb_reg_loss: 1.2408e-05[ 7  8 12  1  7  0 16 15 10 10]\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7070 - l_reg_loss: 0.6896 - bb_reg_loss: 0.0175    \n",
      "Epoch 00003: val_loss improved from 0.88113 to 0.88006, saving model to best_fRCNN_mask_02.keras\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.7070 - l_reg_loss: 0.6896 - bb_reg_loss: 0.0175 - val_loss: 0.8801 - val_l_reg_loss: 0.6930 - val_bb_reg_loss: 0.1871\n",
      "Epoch 4/100\n",
      "[ 8 14 14 16  5 13  9  3 10 13]\n",
      "[ 8 14 14 16  5 13  9  3 10 13]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6882 - l_reg_loss: 0.6882 - bb_reg_loss: 1.2776e-05[ 8 14 14 16  5 13  9  3 10 13]\n",
      " 2/10 [=====>........................] - ETA: 21s - loss: 0.6881 - l_reg_loss: 0.6881 - bb_reg_loss: 1.3447e-05[ 8 14 14 16  5 13  9  3 10 13]\n",
      " 3/10 [========>.....................] - ETA: 20s - loss: 0.6880 - l_reg_loss: 0.6880 - bb_reg_loss: 1.4150e-05[ 8 14 14 16  5 13  9  3 10 13]\n",
      " 4/10 [===========>..................] - ETA: 18s - loss: 0.6879 - l_reg_loss: 0.6879 - bb_reg_loss: 1.4895e-05[ 8 14 14 16  5 13  9  3 10 13]\n",
      " 5/10 [==============>...............] - ETA: 15s - loss: 0.6878 - l_reg_loss: 0.6878 - bb_reg_loss: 1.5678e-05[ 8 14 14 16  5 13  9  3 10 13]\n",
      " 6/10 [=================>............] - ETA: 11s - loss: 0.6878 - l_reg_loss: 0.6877 - bb_reg_loss: 1.6557e-05[ 8 14 14 16  5 13  9  3 10 13]\n",
      " 7/10 [====================>.........] - ETA: 8s - loss: 0.6877 - l_reg_loss: 0.6876 - bb_reg_loss: 1.7569e-05 [ 8 14 14 16  5 13  9  3 10 13]\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 0.6875 - l_reg_loss: 0.6875 - bb_reg_loss: 2.1187e-05[ 8 14 14 16  5 13  9  3 10 13]\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7063 - l_reg_loss: 0.6880 - bb_reg_loss: 0.0184    \n",
      "Epoch 00004: val_loss improved from 0.88006 to 0.87906, saving model to best_fRCNN_mask_02.keras\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.7063 - l_reg_loss: 0.6880 - bb_reg_loss: 0.0184 - val_loss: 0.8791 - val_l_reg_loss: 0.6929 - val_bb_reg_loss: 0.1862\n",
      "Epoch 5/100\n",
      "[ 4 16 10  8  4 10 13 14  7  9]\n",
      "[ 4 16 10  8  4 10 13 14  7  9]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6863 - l_reg_loss: 0.6863 - bb_reg_loss: 2.2417e-05[ 4 16 10  8  4 10 13 14  7  9]\n",
      " 2/10 [=====>........................] - ETA: 18s - loss: 0.6863 - l_reg_loss: 0.6862 - bb_reg_loss: 2.3304e-05[ 4 16 10  8  4 10 13 14  7  9]\n",
      " 3/10 [========>.....................] - ETA: 21s - loss: 0.6862 - l_reg_loss: 0.6861 - bb_reg_loss: 2.4188e-05[ 4 16 10  8  4 10 13 14  7  9]\n",
      " 4/10 [===========>..................] - ETA: 19s - loss: 0.6861 - l_reg_loss: 0.6860 - bb_reg_loss: 2.5090e-05[ 4 16 10  8  4 10 13 14  7  9]\n",
      " 5/10 [==============>...............] - ETA: 16s - loss: 0.6860 - l_reg_loss: 0.6859 - bb_reg_loss: 2.6037e-05[ 4 16 10  8  4 10 13 14  7  9]\n",
      " 6/10 [=================>............] - ETA: 13s - loss: 0.6859 - l_reg_loss: 0.6858 - bb_reg_loss: 2.7019e-05[ 4 16 10  8  4 10 13 14  7  9]\n",
      " 7/10 [====================>.........] - ETA: 9s - loss: 0.6858 - l_reg_loss: 0.6857 - bb_reg_loss: 2.8119e-05 [ 4 16 10  8  4 10 13 14  7  9]\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 0.6856 - l_reg_loss: 0.6855 - bb_reg_loss: 3.1748e-05[ 4 16 10  8  4 10 13 14  7  9]\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7033 - l_reg_loss: 0.6863 - bb_reg_loss: 0.0170    \n",
      "Epoch 00005: val_loss improved from 0.87906 to 0.87802, saving model to best_fRCNN_mask_02.keras\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.7033 - l_reg_loss: 0.6863 - bb_reg_loss: 0.0170 - val_loss: 0.8780 - val_l_reg_loss: 0.6928 - val_bb_reg_loss: 0.1852\n",
      "Epoch 6/100\n",
      "[ 2  3  6 14  7 12  7 13 15 16]\n",
      "[ 2  3  6 14  7 12  7 13 15 16]\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6843 - l_reg_loss: 0.6843 - bb_reg_loss: 3.4902e-05[ 2  3  6 14  7 12  7 13 15 16]\n",
      " 2/10 [=====>........................] - ETA: 21s - loss: 0.6842 - l_reg_loss: 0.6842 - bb_reg_loss: 3.6211e-05[ 2  3  6 14  7 12  7 13 15 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the best fRCNN model name\n",
    "best_model_name = \"best_fRCNN_%s_%02d.keras\" % (MODE, N_SUB)\n",
    "\n",
    "# Model checkpoint for saving best models\n",
    "checkpoint = ModelCheckpoint(best_model_name,\n",
    "                              verbose=1,\n",
    "                              save_best_only=True,\n",
    "                              monitor='val_loss',\n",
    "                              mode='auto')\n",
    "\n",
    "# Model checkpoint for early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               mode='min',\n",
    "                               verbose=1,\n",
    "                               patience=N_PATIENCE)\n",
    "\n",
    "\n",
    "validation_data = generate_validation_data(imgs[:N_VALIDATION_DATA], bbox_datasets[:N_VALIDATION_DATA], IMG_SIZE, N_SUB, N_ANCHORS, ANCHOR_SIZES, ANCHOR_RATIOS, N_RATIOS,\n",
    "                             POS_IOU_THRESHOLD, NEG_IOU_THRESHOLD, DEBUG, POS_RATIO, N_SAMPLES, SHOW_N_POS)\n",
    "\n",
    "model.fit(input_generator(imgs[N_VALIDATION_DATA:], bbox_datasets[N_VALIDATION_DATA:], IMG_SIZE, N_SUB, ANCHOR_RATIOS, ANCHOR_SIZES, N_DATA_EPOCHS, N_ANCHORS, N_RATIOS,\n",
    "                    POS_IOU_THRESHOLD, NEG_IOU_THRESHOLD, DEBUG, POS_RATIO, N_SAMPLES, SHOW_N_POS),\n",
    "          steps_per_epoch=10,\n",
    "          epochs=N_EPOCHS,\n",
    "          callbacks=[checkpoint, early_stopping],\n",
    "          validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8daf90-e78f-41df-a2a1-2c552d3a337f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
