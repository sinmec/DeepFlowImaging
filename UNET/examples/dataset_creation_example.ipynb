{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ed49e-5300-4ee6-ab9c-f0f74cdea9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import cv2 \n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88413f5-01d7-4466-8ec1-6517e6e2cf0a",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e352b8d-8c10-414e-9844-9d76fb917e4b",
   "metadata": {},
   "source": [
    "## First step: Extracting images from the .h5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4ae7f-f9eb-4e66-add9-5d7a6281a0cc",
   "metadata": {},
   "source": [
    "### Importing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9346e-b120-4416-ab2d-80fcf9f304e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\") # TODO: Fix it!\n",
    "from dataset.extract_images_from_h5 import extract_images_from_h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ee84f",
   "metadata": {},
   "source": [
    "### Defining the paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5deeaa-2e9c-48a1-acb9-7ad407bf7599",
   "metadata": {},
   "source": [
    "A `.h5` file containing a U-Net example is provided in this example (`UNET_dataset.h5`).\n",
    "\n",
    "The following U-Net dataset was created using the image annotation tool available [here](https://github.com/sinmec/multilabellerg).\n",
    "\n",
    "The current implementation can read multiple `.h5` files. This is done by simply placing the dataset files in the same` h5_dataset_path` folder.\n",
    "\n",
    "The images are extacted to the `output_path` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dfab6a-ff51-41d3-b205-8eeac7611d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_dataset_path = Path(os.getcwd())\n",
    "output_path = Path(r\"dataset_UNET\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9253f9e",
   "metadata": {},
   "source": [
    "### Running the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d111ab-f97a-4887-a1c4-16b7fcdb13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_images_from_h5(h5_dataset_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810be1c-bd95-42c4-b7e0-b05cc488f394",
   "metadata": {},
   "source": [
    "By running this function, you'll see that it has extracted the raw images (`imgs_full`) and masks (`masks_full`) from the `.h5`  file to the `output_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf57198-5b49-4455-b5a1-a42ae84eb43c",
   "metadata": {},
   "source": [
    "## Second step: Generating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b30c371-779e-4197-a942-c9862ae8e259",
   "metadata": {},
   "source": [
    "### Importing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad399cab-6ead-4ab2-bd45-d3d3cd1afe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.create_dataset import create_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6071ad-6935-4afd-a248-1afbfeed36c0",
   "metadata": {},
   "source": [
    "### Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cccfdb-8113-4cd6-abe6-0f1b2eb40ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the sub-images\n",
    "sub_image_size = 128\n",
    "\n",
    "# Number of random samples\n",
    "random_samples = 64\n",
    "\n",
    "# Number of Validation images\n",
    "N_VALIDATION = 2\n",
    "\n",
    "# Number of Verification images\n",
    "N_VERIFICATION = 2\n",
    "\n",
    "# Path to the dataset\n",
    "path = output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629e39f-1679-4c17-be95-3c0204394d66",
   "metadata": {},
   "source": [
    "The U-Net is trained with sub-images from the original images. For instance, in this example, the \"full\" images have a `(252 x 1024)` shape. However, the U-Net is trained with small portions of these full images. The size of the sub-images is defined by the `sub_image_size` variable. In this example, the sub-images have a size of `(128 x 128)`.\n",
    "\n",
    "In addition to the sub-images, the dataset samples are created in a stochastic manner. First, a random number generator generates a random point located in the image. From this point, a small rectangular sub-image with `sub_image_size` is generated. Then, the area from the mask and raw image is extracted, and a sample (sub-image and mask) is created. This process is repeated `random_samples` times for each full image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03c2ec-ca51-4214-9d16-d4dd5084912e",
   "metadata": {},
   "source": [
    "### Running the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5443f25-3182-472f-ad21-0fc9275e9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(path, sub_image_size, random_samples, N_VALIDATION, N_VERIFICATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8572087-00ff-4ada-b940-021a9ef55272",
   "metadata": {},
   "source": [
    "By running this function, you'll see that it created three new folders on the chosen path:\n",
    " - Training: Samples used during the U-Net training\n",
    " - Validation: Samples used for validation purpouses during training - Total of `N_VALIDATION` full images\n",
    " - Verification: Samples used to evaluate the U-Net accuracy after the training step. Unseen data during training  - Total of `N_VERIFICATION` full images\n",
    " \n",
    "Each folder cotains 4 folders:\n",
    " - `images`: Sub-images with size (`sub_image_size x sub_image_size`) extracted from the raw images\n",
    " - `masks`: Sub-images with size (`sub_image_size x sub_image_size`) extracted from the labelled masks\n",
    "\n",
    "The folder created in this step should be sent to the `UNET/dataset` folder for training.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
