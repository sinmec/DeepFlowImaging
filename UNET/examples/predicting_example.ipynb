{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9aa2bf-80f2-45e0-a66f-2d9b9f7e7825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 18:21:48.241689: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-15 18:21:48.313839: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-15 18:21:49.657768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a8ec34-af94-4f18-8628-e08de7b26ee3",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b683dfc-7588-4138-a146-7098f4b92dbf",
   "metadata": {},
   "source": [
    "## Importing the necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05189443-d650-40ca-bfa9-309411de9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\") # fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91c7dc0f-40ed-4a3c-8477-f9022b7d8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction.apply_UNET_mask_split import apply_UNET_mask\n",
    "from prediction.divide_image import divide_image\n",
    "from prediction.recreate_UNET_image import recreate_UNET_image\n",
    "from prediction.run import get_image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec74064e-2a1c-4fa3-9fe8-2871269d417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(index_img, image_file):\n",
    "    img = cv2.imread(str(Path(image_file_folder, image_file)), 0)\n",
    "    subdivided_image_raw = divide_image(\n",
    "        window_size, sub_image_size, img, stride_division\n",
    "    )\n",
    "\n",
    "    subdivided_image_UNET = apply_UNET_mask(subdivided_image_raw, UNET_model)\n",
    "    img_UNET = recreate_UNET_image(\n",
    "        subdivided_image_UNET, window_size, img, stride_division\n",
    "    )\n",
    "\n",
    "    out_img = np.hstack((img, img_UNET))\n",
    "    cv2.imwrite(str(Path(out_folder, f\"img_{index_img:06d}.jpg\")), out_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d23581-2448-4c3f-9a6f-fd2740ea3fd5",
   "metadata": {},
   "source": [
    "## Getting the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e213c24-3ec7-41ff-9b25-f465aaacf51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_folder = r\"/EXPERIMENTS/HSC_images/22_08_Ql_1_P_1_HIGH_20__001\" # \n",
    "out_folder = Path(\"OUTPUT\")\n",
    "out_folder.mkdir(parents=True, exist_ok=True)\n",
    "image_files = get_image_files(image_file_folder) # This function returns a list which contains the images paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f082ed3c-bb79-4552-a7ae-0446bdd31ae9",
   "metadata": {},
   "source": [
    "## Loading the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f695545-7d6b-4173-a9ec-7f9030ae3cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET_model_file = os.path.join(\"UNET_best.keras\")\n",
    "UNET_model = keras.models.load_model(UNET_model_file, compile=False)\n",
    "window_size = 128\n",
    "sub_image_size = 64\n",
    "stride_division = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b682ad0-4390-4a60-9065-7b392dccc5c5",
   "metadata": {},
   "source": [
    "## Running the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e18ac70a-ab16-443e-b68e-4c3d751ed11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|                               | 0/3200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fc66acf80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 61 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fc66acf80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higorem/DeepFlowImaging/UNET/examples/../prediction/recreate_UNET_image.py:40: RuntimeWarning: invalid value encountered in divide\n",
      "  UNET_image /= UNET_image_nmax\n",
      "/home/higorem/DeepFlowImaging/UNET/examples/../prediction/recreate_UNET_image.py:43: RuntimeWarning: invalid value encountered in cast\n",
      "  UNET_image = UNET_image.astype(np.uint8)\n",
      "Processing images: 100%|████████████████████| 3200/3200 [11:02<00:00,  4.83it/s]\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for index_img, image_file in enumerate(image_files):\n",
    "        future = executor.submit(process_image, index_img, image_file)\n",
    "        futures.append(future)\n",
    "\n",
    "    for future in tqdm(\n",
    "        concurrent.futures.as_completed(futures),\n",
    "        total=len(futures),\n",
    "        desc=\"Processing images\",\n",
    "    ):\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eacbbf-04a3-4518-8829-5730b2be94cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
