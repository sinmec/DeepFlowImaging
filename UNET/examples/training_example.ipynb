{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c83309-a2ab-4f0e-b078-b3a99643fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 15:32:54.877458: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-14 15:32:54.947442: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 15:32:55.979719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2516e-a126-40ee-97f7-b9166244ffd5",
   "metadata": {},
   "source": [
    "# Training UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b741c-406b-439a-a704-dbf3c6b72e17",
   "metadata": {},
   "source": [
    "## Importing the necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c978446-02e3-4b54-b625-92b5abf838c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\") # fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f41d937-5a4f-45f6-942d-a39fb6e75698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.simple.conv2d_block import conv2d_block\n",
    "from training.simple.read_dataset import read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cc1f808-1368-4188-9c47-e31ac77c4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackProgress(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        out_progress_folder = Path(\"progress/best\")\n",
    "        if epoch == 0:\n",
    "            out_progress_folder.mkdir(parents=True, exist_ok=True)\n",
    "        if epoch % 10 == 0:\n",
    "            _images = images_val[::16, :, :].copy()\n",
    "            _masks = masks_val[::16, :, :].copy()\n",
    "\n",
    "            n_tests = _images.shape[0]\n",
    "            _pred_masks = model.predict(_images)\n",
    "\n",
    "            _images *= 255.0\n",
    "            _masks *= 255.0\n",
    "            _pred_masks *= 255.0\n",
    "\n",
    "            for i in range(n_tests):\n",
    "                _img = _images[i, :, :, 0].astype(np.uint8)\n",
    "                _mask = _masks[i, :, :, 0].astype(np.uint8)\n",
    "                _pred_mask = _pred_masks[i, :, :, 0].astype(np.uint8)\n",
    "                _out_img = np.hstack((_img, _mask, _pred_mask))\n",
    "                cv2.imwrite(\n",
    "                    str(\n",
    "                        Path(\n",
    "                            out_progress_folder,\n",
    "                            f\"progress_img_ex_{i:03d}_{epoch:05d}.jpg\",\n",
    "                        )\n",
    "                    ),\n",
    "                    _out_img,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74296146-ce4d-4d3c-8bca-ca813dcc2462",
   "metadata": {},
   "source": [
    "## Defining the path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236b0a78-51ea-4116-80e8-d7ba71e34244",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = Path(r\"/home/higorem/DeepFlowImaging/UNET/examples/dataset_UNET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cdb4c9-2526-45fe-ad44-ce316714f0f0",
   "metadata": {},
   "source": [
    "## Defining hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c3502-ed34-43d4-b307-c2dc07608441",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 64\n",
    "\n",
    "# number of iterations of all the training data in one cycle for training the model\n",
    "EPOCHS = 5000\n",
    "\n",
    "# number of epochs after the loss of the model get lower as possible\n",
    "PATIENCE = 500\n",
    "\n",
    "# number of samples\n",
    "BATCH_SIZE = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa44b5-1381-4713-8300-35ac65c0bf4a",
   "metadata": {},
   "source": [
    "## Reading the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4abb0e-c95b-4aab-a8e8-8d50c1e9c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, masks_train = read_dataset(\n",
    "    dataset_folder, window_size=window_size, subset=\"Training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a10d5f-1313-4fa5-a790-8e150c69e145",
   "metadata": {},
   "source": [
    "## Reading the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4ad5f-8690-4062-ab74-cedbb2fecc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_val, masks_val = read_dataset(\n",
    "    dataset_folder, window_size=window_size, subset=\"Validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14628dc-eb49-4675-9313-4a6b0f216648",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_dataset = images_train.shape[0]\n",
    "shuffle = np.arange(N_dataset)\n",
    "np.random.seed(13)\n",
    "np.random.shuffle(shuffle)\n",
    "images_train = images_train[shuffle, :, :, :]\n",
    "masks_train = masks_train[shuffle, :, :, :]\n",
    "\n",
    "input_img = Input((window_size, window_size, 1), name=\"img\")\n",
    "\n",
    "c1 = conv2d_block(input_img, 8, kernel_size=5, batchnorm=True)\n",
    "p1 = MaxPooling2D((4, 4))(c1)\n",
    "\n",
    "c2 = conv2d_block(p1, 8, kernel_size=5, batchnorm=True)\n",
    "p2 = MaxPooling2D((4, 4))(c2)\n",
    "\n",
    "c3 = conv2d_block(p2, 8, kernel_size=5, batchnorm=True)\n",
    "\n",
    "u4 = Conv2DTranspose(8, kernel_size=5, strides=(4, 4), padding=\"same\")(c3)\n",
    "u4 = concatenate([u4, c2])\n",
    "c4 = conv2d_block(u4, 8, kernel_size=5, batchnorm=True)\n",
    "\n",
    "u5 = Conv2DTranspose(8, kernel_size=5, strides=(4, 4), padding=\"same\")(c4)\n",
    "u5 = concatenate([u5, c1])\n",
    "c5 = conv2d_block(u5, 8, kernel_size=5, batchnorm=True)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(c5)\n",
    "model = Model(inputs=[input_img], outputs=[outputs])\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"min\", verbose=1, patience=PATIENCE\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"UNET_best.keras\", verbose=1, save_best_only=True, monitor=\"val_loss\", mode=\"auto\"\n",
    ")\n",
    "\n",
    "modelo.fit(\n",
    "    images_train,\n",
    "    masks_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(images_val, masks_val),\n",
    "    callbacks=[checkpoint, early_stopping, TrackProgress()],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
